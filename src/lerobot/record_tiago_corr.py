#!/usr/-bin/env python
# -*- coding: utf-8 -*-
"""
Records a dataset using the Tiago robot. Actions are generated by teleoperation.

This script is an adaptation of the general `record.py` script from the LeRobot framework,
specifically configured for use with the `tiago_client`.

This version imports the necessary action mapping and formatting functions directly
from `teleoperate_tiago.py` to ensure consistent control logic.

Example Usage:

```shell
python record_tiago.py \
    --remote_ip="10.68.0.1" \
    --cameras='{my_camera: {type: realsense, width: 640, height: 480, fps: 30}}' \
    --teleop.type=so101_leader \
    --teleop.port=/dev/tty.usbmodem1234561 \
    --dataset.repo_id="your-hf-username/tiago-pick-and-place" \
    --dataset.num_episodes=10 \
    --dataset.single_task="Pick up the red block from the table" \
    --display_data=true
```

Before running, ensure the `tiago_host.py` script is running on the robot's computer.
"""

import logging
import time
from dataclasses import asdict, dataclass, field
from pathlib import Path
from pprint import pformat

# LeRobot imports
from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig
from lerobot.configs import parser
from lerobot.configs.policies import PreTrainedConfig
from lerobot.datasets.image_writer import safe_stop_image_writer
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.datasets.utils import build_dataset_frame, hw_to_dataset_features
from lerobot.datasets.video_utils import VideoEncodingManager
from lerobot.policies.factory import make_policy
from lerobot.policies.pretrained import PreTrainedPolicy
from lerobot.robots import Robot, RobotConfig, make_robot_from_config
from lerobot.teleoperators import Teleoperator, TeleoperatorConfig, make_teleoperator_from_config
from lerobot.utils.control_utils import (
    init_keyboard_listener,
    is_headless,
    predict_action,
    sanity_check_dataset_name,
    sanity_check_dataset_robot_compatibility,
)
from lerobot.utils.robot_utils import busy_wait
from lerobot.utils.utils import (
    get_safe_torch_device,
    init_logging,
    log_say,
)
from lerobot.utils.visualization_utils import _init_rerun, log_rerun_data

# Import Tiago client to ensure it's registered with the factory
from .robots.tiago.tiago_client import TiagoClient  # noqa: F401
from .robots.tiago.config_tiago import TiagoClientConfig  # noqa: F401

# Import the SO-101 leader teleoperator
from lerobot.teleoperators import so101_leader  # noqa: F401

# Import camera configs
from lerobot.cameras import CameraConfig

# Import action mapping and formatting functions from teleoperate_tiago
from .teleoperate_tiago import get_tiago_joint_limits, map_leader_to_tiago, format_action_for_tiago

import numpy as np

# Send an initial action to establish the connection before trying to get observations
DEFAULT_TORSO_POS = 0.30  # meters
DEFAULT_ARM_POSITIONS = [1.61, -0.93, -3.14, 1.83, -1.58, -0.62, -1.58]  # radians


@dataclass
class DatasetRecordConfig:
    """Configuration for recording a dataset."""

    repo_id: str
    single_task: str
    root: str | Path | None = None
    fps: int = 30
    episode_time_s: int | float = 5
    reset_time_s: int | float = 5  # Reduced reset time for manual reset
    num_episodes: int = 20
    video: bool = True
    push_to_hub: bool = True
    private: bool = False
    tags: list[str] | None = None
    num_image_writer_processes: int = 0
    num_image_writer_threads_per_camera: int = 4
    video_encoding_batch_size: int = 1

    # Tiago-specific arguments
    #remote_ip: str = "10.68.0.1"
    remote_ip: str = "172.17.0.2"
    #cameras: dict[str, CameraConfig] = field(default_factory=dict)
    cameras: dict[str, CameraConfig] = field(
        default_factory=lambda: {
            "left": OpenCVCameraConfig(
                index_or_path=4,
                width=640,
                height=480,
                fps=30
            )
        }
    )

    def __post_init__(self):
        if self.single_task is None:
            raise ValueError("You must provide a task description in `single_task`.")


@dataclass
class RecordConfig:
    """Top-level configuration for the recording script."""

    dataset: DatasetRecordConfig
    teleop: TeleoperatorConfig | None = None
    policy: PreTrainedConfig | None = None
    display_data: bool = False
    play_sounds: bool = True
    resume: bool = False

    def __post_init__(self):
        # Dynamically load policy config if a path is provided
        policy_path = parser.get_path_arg("policy")
        if policy_path:
            try:
                # First try to parse as a config file
                cli_overrides = parser.get_cli_overrides("policy")
                self.policy = PreTrainedConfig.from_pretrained(policy_path, cli_overrides=cli_overrides)
                self.policy.pretrained_path = policy_path
            except Exception:
                # If that fails, create a basic PreTrainedConfig with the path
                self.policy = PreTrainedConfig(
                    pretrained_path=policy_path,
                    # Default values for required fields
                    model_type="diffusion",
                    action_horizon=1
                )

        if self.teleop is None and self.policy is None:
            raise ValueError("A teleoperator or a policy is required to control the robot.")

    @classmethod
    def __get_path_fields__(cls) -> list[str]:
        return ["policy"]


@safe_stop_image_writer
def record_loop(
    robot: Robot,
    events: dict,
    fps: int,
    dataset: LeRobotDataset | None = None,
    teleop: Teleoperator | None = None,
    policy: PreTrainedPolicy | None = None,
    control_time_s: int | float | None = None,
    single_task: str | None = None,
    display_data: bool = False,
):
    """Main control loop for recording or resetting."""
    if dataset is not None and dataset.fps != fps:
        raise ValueError(f"The dataset fps should be equal to requested fps ({dataset.fps} != {fps}).")

    if policy is not None:
        policy.reset()

    timestamp = 0
    start_episode_t = time.perf_counter()
    
    # Get joint limits for mapping
    joint_limits = get_tiago_joint_limits()
    
    # Create an initial neutral action using the default positions
    initial_action = {
        'arm_joint_positions': DEFAULT_ARM_POSITIONS,
        'torso_lift_joint.pos': DEFAULT_TORSO_POS,
        'base_linear_velocity': 0.0,
        'base_angular_velocity': 0.0,
        'gripper_command': 1,  # 1 = open
    }
    
    # Send the initial action to establish connection and get first observation
    print("Sending initial action to establish connection...")
    robot.send_action(initial_action)
    print("Initial action sent successfully")
    
    while timestamp < control_time_s:
        start_loop_t = time.perf_counter()

        if events["exit_early"]:
            events["exit_early"] = False
            break

        observation = robot.get_observation()

        if policy is not None or dataset is not None:
            observation_frame = build_dataset_frame(dataset.features, observation, prefix="observation")

        # if policy is not None:
        #     action_values = predict_action(
        #         observation_frame,
        #         policy,
        #         get_safe_torch_device(policy.config.device),
        #         policy.config.use_amp,
        #         task=single_task,
        #     )
            
        #     # Print debug info about policy outputs
        #     print(f"Policy output shape: {action_values.shape}")
            
        #     # Handle policy action based on output size
        #     if len(action_values) >= 3:
        #         # Use the available policy values for the 3 components it was trained on
        #         action = {
        #             'arm_joint_positions': DEFAULT_ARM_POSITIONS.copy(),
        #             'torso_lift_joint.pos': action_values[0].item(),
        #             'base_linear_velocity': action_values[1].item(),
        #             'base_angular_velocity': action_values[2].item(),
        #             'gripper_command': 1,  # Default open gripper
        #         }
        #     else:
        #         print(f"WARNING: Policy output has unexpected size: {len(action_values)}")
        #         action = {
        #             'arm_joint_positions': DEFAULT_ARM_POSITIONS.copy(),
        #             'torso_lift_joint.pos': DEFAULT_TORSO_POS,
        #             'base_linear_velocity': 0.0,
        #             'base_angular_velocity': 0.0,
        #             'gripper_command': 1,  # Default open gripper
        #         }

        # Update the policy action handling in the record_loop function
        if policy is not None:
            action_values = predict_action(
                observation_frame,
                policy,
                get_safe_torch_device(policy.config.device),
                policy.config.use_amp,
                task=single_task,
            )
            
            # Print debug info about policy outputs
            print(f"Policy output shape: {action_values.shape}")
            
            # Handle policy action based on output size
            if len(action_values) >= 12:
                # The policy is outputting all 12 dimensions
                # Create action dictionary but FORCE base velocities to zero
                action = {
                    'arm_joint_positions': [
                        action_values[0].item(),  # arm_1_joint.pos
                        action_values[1].item(),  # arm_2_joint.pos
                        action_values[2].item(),  # arm_3_joint.pos
                        action_values[3].item(),  # arm_4_joint.pos
                        action_values[4].item(),  # arm_5_joint.pos
                        action_values[5].item(),  # arm_6_joint.pos
                        action_values[6].item(),  # arm_7_joint.pos
                    ],
                    'torso_lift_joint.pos': action_values[7].item(),
                    'base_linear_velocity': 0.0,  # FORCE to zero, ignoring policy output
                    'base_angular_velocity': 0.0,  # FORCE to zero, ignoring policy output
                    # Use finger positions to determine gripper command
                    'gripper_command': 2 if action_values[8].item() < 0.01 else 1,
                }
            elif len(action_values) >= 3:
                # For backward compatibility with 3D action policies
                action = {
                    'arm_joint_positions': DEFAULT_ARM_POSITIONS.copy(),
                    'torso_lift_joint.pos': action_values[0].item(),
                    'base_linear_velocity': 0.0,  # FORCE to zero, ignoring policy output
                    'base_angular_velocity': 0.0,  # FORCE to zero, ignoring policy output
                    'gripper_command': 1,  # Default open gripper
                }
            else:
                print(f"WARNING: Policy output has unexpected size: {len(action_values)}")
                action = {
                    'arm_joint_positions': DEFAULT_ARM_POSITIONS.copy(),
                    'torso_lift_joint.pos': DEFAULT_TORSO_POS,
                    'base_linear_velocity': 0.0,
                    'base_angular_velocity': 0.0,
                    'gripper_command': 1,  # Default open gripper
                }
                
        elif teleop is not None:
            # Get raw action from teleoperator
            raw_action = teleop.get_action()
            # Map and format the action for the Tiago robot
            mapped_action = map_leader_to_tiago(raw_action, joint_limits)
            action = format_action_for_tiago(mapped_action)
        else:
            logging.info("No teleoperator provided, skipping action generation during reset.")
            time.sleep(1 / fps)
            continue

        sent_action = robot.send_action(action)


# Then modify the action frame creation section in record_loop:

        if dataset is not None:
            # Transform sent_action to match the observation structure
            flattened_action = {
                'arm_1_joint.pos': sent_action['arm_joint_positions'][0],
                'arm_2_joint.pos': sent_action['arm_joint_positions'][1],
                'arm_3_joint.pos': sent_action['arm_joint_positions'][2],
                'arm_4_joint.pos': sent_action['arm_joint_positions'][3],
                'arm_5_joint.pos': sent_action['arm_joint_positions'][4],
                'arm_6_joint.pos': sent_action['arm_joint_positions'][5],
                'arm_7_joint.pos': sent_action['arm_joint_positions'][6],
                'torso_lift_joint.pos': sent_action['torso_lift_joint.pos'],
                'gripper_left_finger_joint.pos': 0.045,  # Default open position
                'gripper_right_finger_joint.pos': 0.045,  # Default open position
                'base_linear_x.vel': sent_action['base_linear_velocity'],
                'base_angular_z.vel': sent_action['base_angular_velocity']
            }
            
            # If gripper_command is close (2), set finger positions to closed
            if sent_action['gripper_command'] == 2:
                flattened_action['gripper_left_finger_joint.pos'] = 0.0
                flattened_action['gripper_right_finger_joint.pos'] = 0.0
            
            # Create a custom action array with correct shape
            action_values = np.array([
                flattened_action['arm_1_joint.pos'],
                flattened_action['arm_2_joint.pos'],
                flattened_action['arm_3_joint.pos'],
                flattened_action['arm_4_joint.pos'],
                flattened_action['arm_5_joint.pos'],
                flattened_action['arm_6_joint.pos'],
                flattened_action['arm_7_joint.pos'],
                flattened_action['torso_lift_joint.pos'],
                flattened_action['gripper_left_finger_joint.pos'],
                flattened_action['gripper_right_finger_joint.pos'],
                flattened_action['base_linear_x.vel'],
                flattened_action['base_angular_z.vel']
            ], dtype=np.float32)
            
            # Explicitly reshape to match the expected shape [12] instead of (12,)
            action_values = action_values.reshape([12])  # Use list notation for shape
            
            # Create the frame dictionary with the reshaped array
            frame = {
                **observation_frame,
                'action': action_values
            }
            
            dataset.add_frame(frame, task=single_task)

        if display_data:
            log_rerun_data(observation, action)

        dt_s = time.perf_counter() - start_loop_t
        busy_wait(1 / fps - dt_s)

        timestamp = time.perf_counter() - start_episode_t


@parser.wrap()
def record(cfg: RecordConfig) -> LeRobotDataset:
    """Main function to run the recording process."""
    init_logging()
    logging.info(pformat(asdict(cfg)))
    if cfg.display_data:
        _init_rerun(session_name="tiago_recording")

    # Initialize the Tiago client with hardcoded configuration
    robot_config = TiagoClientConfig(
        remote_ip=cfg.dataset.remote_ip,
        cameras=cfg.dataset.cameras,
    )
    robot = TiagoClient(robot_config)

    teleop = make_teleoperator_from_config(cfg.teleop) if cfg.teleop is not None else None

    # Define custom action features to match observation features exactly
    custom_action_features = {
        'action': {
            'dtype': 'float32',
            'shape': (12,),
            'names': [
                'arm_1_joint.pos',
                'arm_2_joint.pos',
                'arm_3_joint.pos',
                'arm_4_joint.pos',
                'arm_5_joint.pos',
                'arm_6_joint.pos',
                'arm_7_joint.pos',
                'torso_lift_joint.pos',
                'gripper_left_finger_joint.pos',
                'gripper_right_finger_joint.pos',
                'base_linear_x.vel',
                'base_angular_z.vel'
            ]
        }
    }

    # Use custom action features instead of robot's action_features
    obs_features = hw_to_dataset_features(robot.observation_features, "observation", cfg.dataset.video)
    dataset_features = {**custom_action_features, **obs_features}
    
    print("Robot Observation Features:", pformat(robot.observation_features))
    print("Robot Action Features:", pformat(robot.action_features))
    print("Dataset Features:", pformat(dataset_features))

    if cfg.resume:
        dataset = LeRobotDataset(
            cfg.dataset.repo_id,
            root=cfg.dataset.root,
            batch_encoding_size=cfg.dataset.video_encoding_batch_size,
        )
        if hasattr(robot, "cameras") and len(robot.cameras) > 0:
            dataset.start_image_writer(
                num_processes=cfg.dataset.num_image_writer_processes,
                num_threads=cfg.dataset.num_image_writer_threads_per_camera * len(robot.cameras),
            )
        sanity_check_dataset_robot_compatibility(dataset, robot, cfg.dataset.fps, dataset_features)
    else:
        sanity_check_dataset_name(cfg.dataset.repo_id, cfg.policy)
        dataset = LeRobotDataset.create(
            cfg.dataset.repo_id,
            cfg.dataset.fps,
            root=cfg.dataset.root,
            robot_type=robot.name,
            features=dataset_features,
            use_videos=cfg.dataset.video,
            image_writer_processes=cfg.dataset.num_image_writer_processes,
            image_writer_threads=cfg.dataset.num_image_writer_threads_per_camera * len(robot.cameras),
            batch_encoding_size=cfg.dataset.video_encoding_batch_size,
        )

    policy = None if cfg.policy is None else make_policy(cfg.policy, ds_meta=dataset.meta)

    robot.connect()
    if teleop is not None:
        teleop.connect()

    listener, events = init_keyboard_listener()

    with VideoEncodingManager(dataset):
        recorded_episodes = 0
        while recorded_episodes < cfg.dataset.num_episodes and not events["stop_recording"]:
            log_say(f"Recording episode {dataset.num_episodes}", cfg.play_sounds)
            record_loop(
                robot=robot,
                events=events,
                fps=cfg.dataset.fps,
                teleop=teleop,
                policy=policy,
                dataset=dataset,
                control_time_s=cfg.dataset.episode_time_s,
                single_task=cfg.dataset.single_task,
                display_data=cfg.display_data,
            )

            if not events["stop_recording"] and (
                (recorded_episodes < cfg.dataset.num_episodes - 1) or events["rerecord_episode"]
            ):
                log_say("Reset the environment", cfg.play_sounds)
                record_loop(
                    robot=robot,
                    events=events,
                    fps=cfg.dataset.fps,
                    teleop=teleop,
                    control_time_s=cfg.dataset.reset_time_s,
                    single_task=cfg.dataset.single_task,
                    display_data=cfg.display_data,
                )

            if events["rerecord_episode"]:
                log_say("Re-record episode", cfg.play_sounds)
                events["rerecord_episode"] = False
                events["exit_early"] = False
                dataset.clear_episode_buffer()
                continue

            dataset.save_episode()
            recorded_episodes += 1

    log_say("Stop recording", cfg.play_sounds, blocking=True)

    robot.disconnect()
    if teleop is not None:
        teleop.disconnect()

    if not is_headless() and listener is not None:
        listener.stop()

    if cfg.dataset.push_to_hub:
        dataset.push_to_hub(tags=cfg.dataset.tags, private=cfg.dataset.private)

    log_say("Exiting", cfg.play_sounds)
    return dataset


def main():
    record()


if __name__ == "__main__":
    main()